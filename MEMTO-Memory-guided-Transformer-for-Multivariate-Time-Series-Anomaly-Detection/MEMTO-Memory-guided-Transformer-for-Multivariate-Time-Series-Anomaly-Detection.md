#### **해당 논문은 [NeurIPS](https://paperswithcode.com/conference/neurips-2023-11) 컨퍼런에 기재된 논문입니다.**

#### **저자- [Junho Song](https://paperswithcode.com/author/junho-song) 외 4인**

1.  **Introduction**
    1.  이상 탐지의 과제: 중요 인프라의 다양한 센서에서 발생하는 시계열 데이터에서 이상 탐지는 데이터 불균형으로 인해 복잡하고 레이블이 지정되지 않은 이상이 많다. 각 시점의 데이터가 정상인지 비정상인지 식별하는 것이 목표이다.
    2.  비지도 학습 접근법: 이상 징후는 레이블이 지정되지 않은 경우가 많기 때문에, 모델이 정상 데이터로만 훈련되는 비지도 학습 작업으로 접근한다. 이 접근법은 훈련 중 이상 징후에 대한 사전 지식을 가정하지 않는다.
    3.  전통적인 방법과 현대적인 방법:
        1.  one-class SVM 및 isolation forest와 같은 전통적인 방법은 널리 사용되었지만 시계열 데이터에서 복잡한 시간 역학 및 변수 간의 상관 관계를 포착하는 데 어려움을 겪고 있다.
        2.  현대의 딥러닝 방법 이러한 한계를 해결한다. Deep SVDD와 같은 기술은 복잡한 시간 의존성을 포착하기 위해 심층 신경망을 사용하여 정상적인 데이터 패턴을 더 효과적으로 모델링하려고 한다.
    4.  Reconstruction 기반 방법: 최근 연구에서 주요 초점은 이것들이다. 이들은 입력 데이터를 재구성하고 재구성 오류를 기반으로 이상 징후를 탐지하는 방식으로 작동한다. 높은 오류는 일반적으로 이상 징후를 나타낸다. 그러나 비정상적인 입력조차도 너무 정확하게 재구성되는 과도한 일반화를 겪을 수 있다.
    5.  MEMTO - 새로운 방법: 이 논문은 메모리 유도 변환기를 의미하는 MEMTO라는 새로운 모델을 소개한다. 이 모델은 다음과 같은 몇 가지 혁신적인 특징을 포함한다:
        1.  Gateed Memory Module: 정상 패턴의 프로토타입 특징을 저장하여 이러한 저장된 표준과 수신 데이터를 비교하여 모델이 정상 패턴과 비정상 패턴을 더 잘 구별할 수 있도록 도와준다.
    6.  효과 및 기여:
        1.  이 접근 방식은 최첨단 결과와 함께 5개의 벤치마크 데이터 세트에서 테스트되어 실제 시나리오에서 효과를 입증한다.
        2.  이 모델은 다변량 시계열에서 이상 탐지의 견고성과 정확성을 향상시켜 기존 방법에 비해 상당한 발전을 제공한다.
2.  **Related work**
    1.  메모리 네트워크 기반: 메모리 네트워크는 동적으로 작성하고 검색할 수 있는 외부 메모리 구성 요소를 포함하는 고급 프레임워크이다. 이를 통해 모델은 과거 정보를 효과적으로 기억하고 활용할 수 있으며, 이는 시간이 지남에 따라 또는 복잡한 데이터 세트에 걸쳐 이해가 필요한 작업에 매우 중요하다.
    2.  개발 및 발전:
        1.  이 개념은 훈련 중에 상당한 수동 조정과 감독이 필요한 기본 메모리 네트워크에서 시작되었다.
        2.  모델이 특정 입력에 응답하여 메모리의 관련 부분에 집중할 수 있도록 하는 주의 메커니즘을 통합함으로써 개선이 이루어졌다. 이러한 개선은 정보의 보다 효율적인 검색을 가능하게 하고 종단 간 훈련 설정을 허용함으로써 광범위한 지도 훈련의 필요성을 감소시킨다.
    3.  전체 분야 애플리케이션:
        1.  자연어 처리(NLP): 메모리 네트워크는 사용자 질문에 답하기 위해 모델이 관련 정보를 기억할 수 있는 질문 답변과 같은 NLP 애플리케이션에서 특히 성공적이었다.
        2.  컴퓨터 비전: 이 영역에서 메모리 네트워크는 비디오 표현 학습, one-shot 학습(단일 예에서 객체 인식), 텍스트-이미지 합성과 같은 작업을 용이하게 한다.
        3.  컴퓨터 비전의 이상 탐지: 메모리 네트워크는 정상적인 패턴이 어떻게 생겼는지 학습하고 기억함으로써 시각 데이터의 이상을 식별하는 데 도움이 된다.
    4.  메모리 자동 인코더 및 이상 탐지:
        1.  MemAE와 같은 이상 탐지의 초기 구현은 정상 패턴과 비정상 패턴을 구별하는 데 도움이 되도록 메모리 네트워크를 오토인코더 아키텍처에 통합했다. 그러나 이러한 초기 버전은 새로운 데이터를 기반으로 저장된 메모리를 업데이트하는 강력한 방법이 없었다.
        2.  MNAD와 같은 이후 모델들은 새로운 데이터로 메모리를 능동적으로 업데이트하는 방법을 소개했다. 이러한 업데이트는 각 메모리 항목에 관련 쿼리의 가중합을 추가하는 것을 수반하지만, 이 방법은 들어오는 데이터의 신규성이나 관련성에 기초한 제어된 업데이트를 허용하지 않았다.
    5.  MEMTO의 게이트 메모리 모듈:
        1.  Gated memory module은 이상 탐지를 위한 메모리 네트워크 응용 분야에서 상당한 발전이다. 메모리 항목을 업데이트하기 위한 데이터 기반 메커니즘을 도입함으로써 이전 모델보다 개선된다.
        2.  이 모듈은 "업데이트 게이트"를 사용하여 새로운 노멀 데이터에 대응하여 각 메모리 항목을 얼마나 변경해야 하는지 제어한다. 이는 메모리가 수동적으로 정보를 저장하는 것에 그치지 않고 가장 관련성이 높고 현재의 노멀 패턴을 반영하도록 능동적으로 적응하도록 보장한다.

![asd](MEMTO-Memory-guided-Transformer-for-Multivariate-Time-Series-Anomaly-Detection/picture/1.png)
-   업데이트 메커니즘(녹색 ▷◁ 심볼) 및 새로운 데이터를 저장된 메모리에 통합하는 프로세스(빨간색 ⊕ 심볼)가 제공된 그림에 시각화 된다. 이들은 쿼리가 검색된 메모리 아이템과 결합되는 방식, 및 메모리 업데이트 단계가 제어되는 방식을 예시로 보여준다.
-   두 개의 완전히 연결된 계층으로 구성된 언급된 "Wak Decoder"는 이상 징후를 나타내는 불일치를 탐지하는 데 초점을 맞추어 업데이트 된 메모리로부터의 입력을 재구성하는 역할을 할 가능성이 높다.

3.  **Method**
    1.  시계열 데이터의 정의:
        1.  Raw 시계열(D): 전체 데이터 세트인 D는 N개의 하위 시리즈로 구성되며, 여기서 각 하위 시리즈 $X^s$는 L개의 타임스텝의 시퀀스이며, 각 타임스텝은 ${R}^{n \\}$의 벡터 $x_t^s$이다. 여기서 $\\(n \\)$는 각 타임스텝에서 데이터의 입력 차원이다.
    2.  인코더 및 쿼리 벡터:
        1.  데이터가 시스템을 통해 흐를 때 하위 시리즈의 각 타임스텝 벡터 $\\( x_t^s \\)$는 인코더에 의해 처리된다. 각 타임스텝에 대한 인코더의 출력은 $\\( {R}^C \\)$의 특징 벡터 $\\(q_t^s \\)$이며, 여기서 $\\( C \\)$는 잠재 차원이다. 이 벡터는 게이트 메모리 모듈에서 메모리 항목을 검색하거나 업데이트하기 위한 쿼리 역할을 한다.
    3.  Gated Memory Module:
        1.  Gated Memory Module은 아키텍처에서 중요한 역할을 한다. 쿼리 벡터 $q_t^s$와 상호 작용하여 메모리 항목을 검색하거나 업데이트하여 정상 데이터의 패턴을 효과적으로 인식하는 방법을 학습한다.
    4.  디코더 및 메모리 상호 작용:
        1.  Gated Memory Module의 출력들은, 쿼리 벡터들과 함께, 디코더로 공급된다. 디코더는 입력 서브-시리즈의 업데이트된 버전에 대응하는 시퀀스 $(q_s^s )$를 생성하기 위해 이들 쿼리 벡터들을 업데이트한다. 본질적으로, 디코더는 이들 업데이트된 쿼들을 입력 공간으로 다시 맵핑하려고 한다.
    5.  출력:
        1.  디코더로부터의 최종 출력은 입력 서브 시리즈 $(X^s )$의 재구성된 버전이며, 이는 $(X_s^s )$로 표현된다. 이 출력은 원래 입력 데이터와 비교하여 이상을 식별하는 데 사용된다.

3.1.1 **Encoder and decoder**

-   Encoder: Transformer-Based Architecture:
    -   Transformer Encoder: MEMTO의 인코더는 시계열 데이터에서 장기적이고 복잡한 시간 패턴을 포착하는 데 매우 효과적인 Transformer Architecture를 사용한다. 이러한 유형의 아키텍처는 데이터 시퀀스를 처리하기 위해 자기 주의와 같은 메커니즘을 사용하여 시퀀스에서 멀리 떨어져 있는 경우에도 서로 다른 시점에 걸친 종속성과 관계를 이해할 수 있다.
-   잠재 공간 투영: 여기서 Transformer Encoder의 역할은 입력된 하위 계열을 잠재 공간에 투영하는 것이다. 이는 원시 입력 데이터를 모델에 의한 추가 처리에 필요한 필수 정보를 포착하는 보다 추상적인 표현(잠재 벡터)으로 변환한다는 것을 의미한다.
-   Decoder: 단순성이 핵심:
    -   Weak Decoder: MEMTO 모델의 디코더는 인코더와 달리 완전히 연결된 두 개의 레이어로만 구성된 의도적으로 단순하게 설계되었다. 이 단순함은 디코더가 지나치게 강력해지지 않도록 보장하는 데 매우 중요하다.
    -   Weak Decoder의 합리적인 이유: 텍스트는 디코더가 너무 강하면(심층이 많은 경우를 의미함) 인코더가 제공하는 잠재 벡터의 품질에 관계없이 입력 데이터를 스스로 너무 정확하게 재구성할 수 있음을 강조한다. 최악의 경우, 매우 강한 디코더는 실제 데이터에 대한 의미 있는 정보를 포함하지 않는 부실 입력이나 무작위 입력에서도 정확한 출력을 생성할 수 있다. 이는 인코더에서 의미 있는 표현을 학습하는 목적을 상실하고 인코더에서 과적합 또는 부적절한 학습과 같은 문제를 가릴 수 있다.
-   인코더와 디코더 간의 균형:
    -   인코더의 인코딩 능력과 디코더의 디코딩 능력 사이의 균형은 매우 중요하다. 더 간단한 디코더는 모델 전체의 성능이 시계열 데이터에서 관련 패턴을 효과적으로 캡처하고 인코딩하는 인코더의 능력에 더 의존하도록 보장한다. 이 설정은 모델이 데이터를 정말로 이해하는 법을 배우도록 보장하고, 잘못된 입력에서 좋은 출력을 생성하게 한다.

**3.1.2 Gated memory module**

**Gated memory module의 용도**:

과다 일반화 문제: 재구성 기반 모델에서 모델은 정상 패턴 이상으로 일반화되기 때문에 이상 징후를 포함한 모든 입력을 너무 잘 재구성하는 법을 배울 수 있다. 이 경우 정상 데이터와 비정상 데이터를 효과적으로 구분하지 못할 수 있다.

-   -   데이터 기반 조정: Gated memory module은 제어되고 데이터 기반의 방식으로 다양한 정상 패턴에 적응하고 학습하도록 도입되었다. 이는 모델이 정상 데이터 특성에 초점을 유지하도록 돕고 이상 징후를 식별하는 데 있어 모델의 특수성을 향상시킨다.

메모리 모듈의 기능:

-   원형 특징의 저장: 메모리 모듈의 각 항목은 데이터 세트에 대해 정상적인 것으로 간주되는 것의 원형 특징을 저장한다. 이러한 특징은 정상적인 조건에서 입력 데이터가 일반적으로 어떻게 보여야 하는지에 대한 벤치마크 또는 기준점 역할을 한다.
-   정규화 역할: 모듈은 재구성 과정에서 이렇게 저장된 정규화 패턴을 사용함으로써 정규화의 한 형태로 작용한다. 이는 모델의 학습 과정에 제약을 가하여 정규화 패턴과 일치하지 않는 비정상적인 데이터 점에 너무 가깝게 맞추지 못하도록 한다는 것을 의미한다.

2단계 반복 업데이트 프로세스:

-   메모리 항목 업데이트: 모델은 메모리를 두 단계로 업데이트하여 정상 패턴에 대한 이해를 반복적으로 정교화할 수 있다. 이 반복적인 과정은 모델이 시간이 지남에 따라 정상 데이터를 나타내는 정확도를 향상시키는 데 도움이 됩니다.
-   잠재 표현 추출: 이러한 업데이트 중에 모델은 메모리에 저장된 프로토타입 패턴을 기반으로 입력 하위 시리즈의 잠재 표현을 추출하고 정제한다. 이는 모델이 정상 패턴을 더 정확하게 인식하고 재구성하는 능력을 강화하는 동시에 이상 징후를 재구성할 수 있는 능력은 약화시킨다.

이상재건에 미치는 영향:

-   Limiting Encoder's Flexibility: 이 메커니즘은 인코더가 이상 징후의 고유한 속성에 적응하는 능력을 제한하도록 특별히 설계되었다. 이러한 의도적인 제한은 모델이 저장된 정상 패턴에서 크게 벗어나는 데이터를 재구성하기 어렵게 만들어 이상 징후와 같은 편차를 플래그로 지정하는 능력을 향상시킨다.

메모리 항목:

-   모델은 고정된 수의 메모리 항목들을 포함하며, 이들 각각은 정상적인 데이터 패턴들의 프로토타입 특징들을 저장한다. 이러한 메모리 항목들은 모델이 전형적인 (비이상적인) 데이터가 어떻게 보여야 하는지를 식별하는 데 도움을 준다.

Incremental Memory Update 접근 방식:

-   incremental updating 메커니즘이 사용되며, 여기서 메모리 아이템들은 그들이 시간 경과에 따라 수신하는 입력 데이터(쿼리들)에 기초하여 업데이트된다. 이 접근법은 더 많은 데이터가 처리됨에 따라 정상적인 데이터 패턴들을 더 잘 나타내도록 메모리 아이템들을 점진적으로 미세화하는 것을 돕는다.

쿼리 조건 메모리 주의:

-   각각의 타임스탬프에 대해, softmax-based attention 메커니즘이 각각의 메모리 아이템이 현재 쿼리에 의해 얼마나 영향을 받아야 하는지를 결정하기 위해 사용된다. 이것은 다음에 의해 기술된다: $$ 
          
     v_{i,t} = \frac{\exp\left(\frac{m_i \cdot q_t'}{\tau}\right)}{\sum_{p=1}^L \exp\left(\frac{m_p \cdot q_s'}{\tau}\right)}  
     
         $$
-   여기서, $(m_i)$는 메모리 항목을 나타내고$(q_t' )$는 시간 $\\(t \\)$에서의 쿼리이며, $( \tau )$는 소프트맥스 분포의 선명도를 제어하는 데 도움이 되는 온도 하이퍼파라미터이다.

-   게이트 업데이트 $\\( \psi \\)$:  
    \- 업데이트 게이트 $( \psi \\)$는 현재 입력에 기초하여 각 메모리 항목을 업데이트해야 하는 정도를 결정한다. 출력이 0과 1 사이인 것을 보장하기 위해 시그모이드 활성화 함수$(\sigma)$를 사용하여 계산되며, 이는 업데이트를 스케일링한다. 업데이트 게이트는 다음과 같이 정의된다:  
    $$
      
     \psi = \sigma (U_{\psi}m_i + W_{\psi}\sum_{t=1}^L v_{i,t} q_t')  
     
         $$
-   $( U_{\psi} ) 및 ( W_{\psi} )$는 각각 메모리 항목 및 쿼리 벡터의 가중합에 적용되는 선형 변환이다.
-   메모리 항목 업데이트 규칙:
    -   각 메모리 항목의 실제 업데이트는 이전 메모리 상태와 가중치 입력의 선형 조합으로, 업데이트 게이트에 의해 제어된다: $$
      
     m_i \leftarrow (1 - \psi) m_i + \psi \sum_{t=1}^L v_{i,t} q_t'  
     
$$
    -   이 공식은 각 메모리 항목이 들어오는 쿼리의 관련성 및 새로움에 비례하여 업데이트될 수 있게 하여, 오래된 패턴에 대한 가치 있는 정보를 잃지 않고 새로운 정상 패턴에 적응하는 모델의 능력을 향상시킨다.

**Gated memory update stage**

-   쿼리 업데이트 단계:
    -   이 단계에서, 업데이트된 질의들 $\tilde{q}_t'$이 생성된다. 이러한 질의들은 디코더에 대한 입력으로서 역할을 하기 때문에 중요하고, 메모리 모듈로부터 검색된 정보를 통합한다.
-   메모리 조건 쿼리 주의:
    -   각 쿼리 $q_t$에 대해 메모리 조건 주의 메커니즘이 적용된다. 이 주의 메커니즘은 쿼리 $\\( q_t \\)$와 각 메모리 항목 $\\(m_i \\)$ 간의 유사성을 기반으로 가중치 $\\(w_{i,t}^s \\)$를 계산한다. 유사성은 분포의 선명도를 제어하기 위해 온도 매개변수 $\tau$에 요인화된 softmax 함수로 정규화된 도트 곱을 사용하여 정량화된다:  $$
    
     w_{i,t}^s = \frac{\exp\left(\frac{m_i \cdot q_t'}{\tau}\right)}{\sum_{j=1}^M \exp\left(\frac{m_j \cdot q_t'}{\tau}\right)}  
     
    $$
    -   이 공식은 각각의 가중치가 쿼리에 대한 대응하는 메모리 아이템의 관련성을 반영하는 것을 보장한다.
-    검색된 메모리 항목:
    -   가중치가 계산되면 검색된 메모리 항목 $\\( \tilde{q}\_t' \\)$은 가중치$(w_{i,t}^s)$를 사용하여 모든 메모리 항목 $\\(m_i \\)$의 가중치 합으로 계산된다:  $$  
     \tilde{q}_t' = \sum_{i=1}^M w_{i,t}^s m_i  
     $$
    -   이 작업은 쿼리와의 관련성을 기반으로 메모리 항목을 결합하여 시간 \\(t \\)에서 쿼리의 특정 특징에 대한 메모리 검색을 효과적으로 사용자 정의한다.
-   쿼리 및 메모리 통합:
    -   그런 다음 업데이트된 쿼리 $\\( \tilde{q}\_t' \\)$와 검색된 메모리 항목 $\\( \tilde{q}\_t' \\)$이 특징 차원을 따라 연결된다. 이 연결된 벡터는 디코더에 대한 강력한 입력 역할을 한다. 이 단계는 원본 쿼리 정보를 컨텍스트 메모리와 통합하여 현재 및 과거 데이터 패턴 모두로 디코더에 대한 입력을 풍부하게 한다.
-   이상재건에 미치는 영향:
    -   정상 패턴을 반영하는 메모리 항목을 활용하여 모델을 교정함으로써 정상 데이터를 효과적으로 재구성하는 동시에 이상 징후에 대해서는 동일한 작업을 수행하는 것이 어렵다는 것을 알 수 있다. 이러한 어려움은 이상 징후가 메모리에 저장된 일반적인 정상 패턴의 원형과 잘 일치하지 않기 때문이다.
    -   따라서 모델이 이상치를 재구성하려고 할 때 출력이 정상 샘플과 다르게 나타나는 경우가 많아 정상 데이터와 비정상 데이터를 구분하는 모델의 능력을 높이고 과도한 일반화를 방지할 수 있다.

**3.2 Training**

-   재구성손실$\\(L_{rec}\\)$:
    -   Purpose: 교육 중 주요 목표는 원래의 하위 시리즈 $\\(X^s\\)$와 재구성된 하위 시리즈 $\\(X^s\\)$의 차이를 최소화하는 것입니다. 이는 모델이 학습한 정상적인 패턴을 정확하게 재구성할 수 있도록 하는 것을 목표로 한다.
    -   definition: 재구성 손실은 데이터 세트의 모든 N개 샘플에 대한 평균 제곱 오차(L2 손실)로 정의된다:  $$ 
     L_{entr} = \frac{1}{N} \sum_{s=1}^N \sum_{t=1}^L \sum_{i=1}^M -w_{i,t}^s \log(w_{i,t}^s)  
     $$
    -   이 손실은 실제 데이터 포인트와 재구성 간의 차이 제곱의 평균을 측정하여 모델이 입력 데이터를 재구성하는 측면에서 얼마나 잘 수행하고 있는지에 대한 간단한 지표를 제공한다.
-   엔트로피 손실$(L_{entr})$:
    -   Purpose : 주의 가중치 $\\(w_{i,t}^s\\)$의 희소성을 촉진하기 위해, 메모리 항목의 조밀한 행렬에 너무 많이 의존하여 모델이 과적합되지 않도록 한다. 희소한 주의 가중치는 가장 관련성이 높은 메모리 항목에만 초점을 맞추는 데 도움이 되어 과도하게 일반화될 가능성을 줄인다.
    -   definition: 엔트로피 손실은 주의 가중치를 정규화하기 위한 보조 손실로 사용된다:  $$ 
     L_{entr} = \frac{1}{N} \sum_{s=1}^N \sum_{t=1}^L \sum_{i=1}^M -w_{i,t}^s \log(w_{i,t}^s)  
     $$
    -   이 공식은 주의 가중치에 대한 엔트로피를 계산하여 가중치의 분포가 관련 없는 메모리 항목에 대해 매우 낮거나 0이 되도록 장려하고, 따라서 모델이 재구성하는 동안 고려하는 메모리에 대해 선택적이 되도록 추진한다.
-   목적 함수$(L)$:
    -   손실의 조합: 모델 훈련을 위한 전체 목적 함수는 가중치 매개변수 $\\(\lambda\\)$에 의해 균형을 이루는 재구성 손실과 엔트로피 손실의 조합이다:  $$  
     L = L_{rec} + \lambda L_{entr}  
     $$
    -   Lambda $(\lambda)$: 이 매개변수는 재구성 정확도의 중요성과 메모리 항목 사용의 희소성의 균형을 유지한다.$\lambda$를 조정하면 입력을 정확하게 재구성하는 것과 메모리 항목의 간결한 사용 사이에서 모델의 초점을 조정할 수 있다.

**Initializing memory items with K-means clustering**

-   1단계: 자체 지도 학습 및 쿼리 생성
    -   목표: 첫 번째 단계에서는 입력 데이터를 재구성하는 작업에만 초점을 맞추어 MEMTO 모델을 자체 감독 방식으로 훈련하는 것이 목표이다.
    -   Process: MEMTO 모델의 훈련된 인코더는 훈련 데이터의 10%를 무작위로 샘플링하여 쿼리를 생성한다. 이러한 쿼리는 인코더에 의해 해석되는 바와 같이 입력 데이터로부터 파생된 중요한 특징 또는 패턴을 나타낸다.
    -   K-means 클러스터링 사용: 생성된 쿼리는 K-means 알고리즘을 사용하여 클러스터링된다. 이 클러스터의 중심 또는 클러스터 내의 가장 일반적인 패턴을 나타내는 중심은 메모리 항목의 초기 값을 설정하는 데 사용된다. 이는 데이터의 핵심 특성이나 "정상적인 프로토타입 패턴"을 포착하는 데 도움이 된다.
-   2단계: 이상 탐지 교육
    -   목표: K-평균 클러스터링에서 얻은 중심으로 초기화된 메모리 항목을 사용하여 두 번째 단계는 MEMTO 모델을 실제 이상 탐지 작업에 대해 훈련시키는 것이다.
    -   잘 초기화된 메모리 항목의 장점: 이미 정상적인 데이터 패턴에 근접한 메모리 항목부터 시작하면 모델이 편차나 이상을 보다 효과적으로 감지하는 방법을 학습할 수 있는 안정적이고 정보에 입각한 기준선을 가질 수 있다.
-   2단계 접근법의 근거:  
    -   훈련에서의 안정성: K-평균으로 메모리 항목을 초기화하면 무작위 초기화로 인해 발생할 수 있는 불안정성의 위험을 완화하는 데 도움이 된다. 이 안정성은 모델이 오해의 소지가 있는 초기값에서 조정하는 대신 신뢰할 수 있는 시작점에서 점진적으로 메모리 항목을 업데이트할 수 있기 때문에 매우 중요하다.  
        
    -   클러스터링 방법의 유연성: 이 접근법에서는 K-means를 클러스터링의 기본 방법으로 사용하지만, 프레임워크는 유연하고 특정 유형의 데이터 세트에 더 적합한 경우 다른 클러스터링 알고리즘을 사용할 수 있다. 이러한 적응성은 데이터 세트마다 고유 특성(예: 분포, 밀도 또는 이상 징후 유형)에 따라 최적의 클러스터링 솔루션이 다를 수 있기 때문에 유용하다.

**3.4 Anomaly criterion**

-    잠재 공간 편차(LSD):  
    -   Definition: LSD는 각 쿼리 $\\(q_t'\\)$와 잠재 공간 $\\(m_t^{s,pos}\\)$에서 가장 가까운 메모리 항목 사이의 각 시점 $\\(t\\)$에서 편차를 측정한다. 이 가장 가까운 메모리 항목은 모델에 저장된 프로토타입 정규 패턴을 나타낸다.  
        -   식:  
              $$  
     LSD(q_t', m) = \|q_t' - m_t^{s,pos}\|^2  
     $$
    -   Purpose: 편차가 클수록 당시 쿼리가 정상 동작의 가장 가까운 프로토타입과 상당히 다르다는 것을 나타내며, 이는 잠재적인 이상 현상을 시사한다.
-   입력 공간 편차(ISD):  
    -   definition: ISD는 시간$(t)$, $\\(X_t^s\\)$, 재구성된 입력 $(X_t'^s)$사이의 유클리드 거리 제곱을 측정한다.  
        -   식:  
            $$  
     ISD(X_t^s, X_t'^s) = \|X_t^s - X_t'^s\|^2  
      $$
            
    -   Purpose: ISD는 LSD와 마찬가지로 입력 데이터가 모델에 의해 얼마나 잘 재구성되는지 측정하는 기능을 제공한다. 값이 클수록 이상 징후를 나타낼 수 있는 불일치가 발생할 수 있다.  
        
-   LSD와 ISD:  
    -   Method: LSD와 ISD에서 계산된 편차를 조합하여 종합적인 이상 점수를 형성한다. LSD는 ISD 값을 증폭하는 가중 메커니즘으로 사용되어 잠재 표현이 정상 패턴에서 크게 벗어나는 시점을 효과적으로 강조한다.  
        -   식:  
            $$ 
     A(X^s) = \text{softmax}([LSD(q_t', m)]_{t=1,...,L}) \odot [ISD(X_t^s, X_t'^s)]_{t=1,...,L}  
       $$
            
    -   details: 일련의 LSD 값을 정규화하기 위해 Softmax를 적용하여 가중치로 변환한다. 그러면 이 가중치에 ISD 값을 요소별로 곱하여 잠재 편차와 입력 편차가 모두 큰 점의 영향력을 강화한다.
-   목적 및 결과:  
    -   이 접근법은 잠재 표현과 실제 입력 데이터 모두에서 편차를 활용하여 이상 징후를 탐지하기 위한 이중 기준을 활용한다. 이 방법은 표현 및 재구성 차원 모두에서 정상 데이터 패턴으로부터의 이탈을 기반으로 이상 징후를 포착하여 이상 징후 탐지의 민감도와 특이성을 높이는 것을 목표로 한다.  
        
    -   이러한 편차들을 통합함으로써, 검출 방법은 변칙적인 시점들을 보다 효과적으로 식별할 수 있어, 전체적인 검출 성능이 향상될 수 있다.

![](MEMTO-Memory-guided-Transformer-for-Multivariate-Time-Series-Anomaly-Detection/picture/2.png)

**Dataset**

"[ANOMALY TRANSFORMER: TIME SERIES ANOMALY DETECTION WITH ASSOCIATION DISCREPANCY](https://hanjunseojbnu.tistory.com/10 "ANOMALY TRANSFORMER: TIME SERIES ANOMALY DETECTION WITH ASSOCIATION DISCREPANCY")" 논문에 기재된 데이터셋과 동일한 데이터셋을 사용하였다.

![](https://blog.kakaocdn.net/dn/79Yes/btsHnhMFyh6/Rrpw2DuU2GwUFFb9rJBcP0/img.png)

출처: https://hanjunseojbnu.tistory.com/11