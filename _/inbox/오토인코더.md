신경망 아키텍처의 한 종류로, 주로 비지도 학습 방식으로 데이터의 효율적인 표현(인코딩)을 학습하는 데 사용됩니다. 오토인코더는 입력 데이터를 잘 복원할 수 있는 방식으로 내부 표현을 압축하는 목적으로 설계되었습니다.

### 오토인코더의 구조

오토인코더는 크게 세 부분으로 나눌 수 있습니다:

1. **인코더(Encoder)**: 입력 데이터를 내부 표현(잠재 공간)으로 변환하는 역할을 합니다. 이 과정에서 데이터는 보통 더 낮은 차원으로 압축됩니다.
2. **잠재 공간(Latent Space)**: 인코더에 의해 생성된 데이터의 압축된 표현입니다. 이 공간은 입력 데이터의 중요한 특징들을 포착하며, 데이터의 본질적인 구조를 나타내는 데 사용됩니다.
3. **디코더(Decoder)**: 잠재 공간의 표현을 다시 원래의 데이터 차원으로 복원하는 역할을 합니다. 이 과정을 통해 입력 데이터가 재구성됩니다.

### 오토인코더의 주요 용도

1. **차원 축소**: [[PCA]]와 같은 전통적인 차원 축소 기법과 비교했을 때, 오토인코더는 비선형 차원 축소가 가능하다는 장점이 있습니다.
2. **이상 탐지**: 정상적인 데이터만을 사용하여 오토인코더를 훈련시킬 경우, 이상 데이터는 잘 복원되지 않아 재구성 오류가 크게 나타납니다. 이를 통해 이상치를 탐지할 수 있습니다.
3. **데이터 노이즈 제거**: 오토인코더는 노이즈가 섞인 데이터를 입력 받아 노이즈가 제거된 데이터를 재구성할 수 있습니다. 이 과정에서 중요한 데이터 특성은 유지하면서 불필요한 정보를 제거할 수 있습니다.
4. **특성 학습**: 오토인코더는 데이터에서 유용한 특성을 자동으로 학습할 수 있으며, 이 특성들은 다른 머신 러닝 작업에 활용될 수 있습니다.

### 오토인코더의 변형

- **변분 오토인코더(Variational Autoencoder, VAE)**: 일반 오토인코더와 다르게, 입력 데이터의 확률적 모델을 학습하며, 생성 모델로도 활용될 수 있습니다.
- **계약형 오토인코더(Contractive Autoencoder)**: 인코더의 잠재 공간에서 입력 데이터의 작은 변화에도 민감하지 않도록 학습하여, 더 안정적인 특성을 추출할 수 있습니다.
- **스파스 오토인코더(Sparse Autoencoder)**: 활성화 함수를 통해 잠재 공간의 활성화 뉴런 수를 제한함으로써, 중요한 특성만을 강조하는 효과를 냅니다.